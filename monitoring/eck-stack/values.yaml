########################################
# TLS Certificates Configuration (cert-manager)
########################################
certificates:
  enabled: true

  # Organization name for certificate subject
  organization: "Techsecoms Consulting Group LLC"

  # Certificate issuer configuration
  issuer:
    # Create a self-signed CA issuer (set to false if using external issuer like Vault)
    createSelfSigned: true
    # Name of the ClusterIssuer for the self-signed CA
    clusterIssuerName: elastic-system-cert-issuer
    # Name of the namespace Issuer (created from CA)
    issuerName: elastic-system-ca-issuer
    # Secret name for the root CA
    caSecretName: root-ca-secret

  # Elasticsearch certificate
  elasticsearch:
    enabled: true
    secretName: elasticsearch-es-cert
    # Additional DNS names for the certificate
    dnsNames:
    - elasticsearch-es-http
    - elasticsearch-es-http.elastic-system.svc
    - elasticsearch-es-http.elastic-system.svc.cluster.local
    # External hostnames (from ingress)
    externalDnsNames:
    - elasticsearch.ops.techsecom.io
    privateKey:
      algorithm: RSA
      size: 2048

  # Kibana certificate
  kibana:
    enabled: true
    secretName: kibana-tls-cert
    dnsNames:
    - kibana-kb-http
    - kibana-kb-http.elastic-system.svc
    - kibana-kb-http.elastic-system.svc.cluster.local
    externalDnsNames:
    - kibana.ops.techsecom.io
    privateKey:
      algorithm: RSA
      size: 2048

  # Logstash certificate
  logstash:
    enabled: true
    secretName: logstash-tls-cert
    dnsNames:
    - eck-stack-eck-logstash-ls-beats
    - eck-stack-eck-logstash-ls-beats.elastic-system.svc
    - eck-stack-eck-logstash-ls-beats.elastic-system.svc.cluster.local
    - eck-stack-eck-logstash-ls-http
    - eck-stack-eck-logstash-ls-http.elastic-system.svc
    - eck-stack-eck-logstash-ls-http.elastic-system.svc.cluster.local
    privateKey:
      algorithm: RSA
      size: 2048

########################################
# ILM (Index Lifecycle Management) Configuration
########################################
ilm:
  enabled: true
  image: curlimages/curl:latest

  # Elasticsearch connection settings
  elasticsearch:
    serviceName: elasticsearch-es-http
    port: 9200
    secretName: elasticsearch-es-elastic-user
    secretKey: elastic

  # Kibana connection settings
  kibana:
    serviceName: kibana-kb-http
    port: 5601

  # ILM Policies Configuration
  # TESTING VALUES: Using minutes/hours to observe data movement
  # For production, change to days (e.g., "2d", "7d", "30d")
  policies:
    # Audit Logs ILM Policy
    auditLogs:
      name: hot_warm_delete-audit-logs
      hot:
        rollover:
          maxAge: "5m" # Rollover after 5 minutes (testing)
          maxPrimaryShardSize: "1gb" # Or when shard reaches 1GB
          maxDocs: 10000 # Or when 10K docs (testing)
      warm:
        minAge: "10m" # Move to warm after 10 minutes
        replicas: 0 # Reduce replicas in warm
      cold:
        minAge: "30m" # Move to cold after 30 minutes
        replicas: 0 # No replicas in cold
      delete:
        minAge: "1h" # Delete after 1 hour total
        waitForSnapshot: "none" # Set to snapshot policy name if using SLM

    # Container Logs ILM Policy
    containerLogs:
      name: hot_warm_delete-container-logs
      hot:
        rollover:
          maxAge: "5m" # Rollover after 5 minutes (testing)
          maxPrimaryShardSize: "1gb" # Or when shard reaches 1GB
          maxDocs: 10000 # Or when 10K docs (testing)
      warm:
        minAge: "10m" # Move to warm after 10 minutes
        replicas: 0 # Reduce replicas in warm
      cold:
        minAge: "30m" # Move to cold after 30 minutes
        replicas: 0 # No replicas in cold
      delete:
        minAge: "1h" # Delete after 1 hour total
        waitForSnapshot: "none" # Set to snapshot policy name if using SLM

  # Index Templates Configuration
  indexTemplates:
    auditLogs:
      shards: 1
      replicas: 1
      refreshInterval: "5s"
    containerLogs:
      shards: 1
      replicas: 1
      refreshInterval: "5s"

########################################
# Kibana Spaces, Roles, and Role Mappings
########################################
kibana:
  spaces:
    enabled: false
    list:
    - id: "logs"
      name: "Logs"
      description: "Space for log analysis"
      disabledFeatures: []
    - id: "security"
      name: "Security"
      description: "Space for security monitoring"
      disabledFeatures: []

  roles:
    enabled: false
    list:
    - name: "logs_reader"
      definition:
        cluster: []
        indices:
        - names:
          - "container-logs-*"
          - "audit-logs-*"
          privileges:
          - "read"
          - "view_index_metadata"
        applications:
        - application: "kibana-.kibana"
          privileges:
          - "feature_discover.read"
          - "feature_dashboard.read"
          resources:
          - "space:logs"
    - name: "logs_admin"
      definition:
        cluster:
        - "monitor"
        indices:
        - names:
          - "container-logs-*"
          - "audit-logs-*"
          privileges:
          - "all"
        applications:
        - application: "kibana-.kibana"
          privileges:
          - "feature_discover.all"
          - "feature_dashboard.all"
          - "feature_canvas.all"
          - "feature_maps.all"
          - "feature_visualize.all"
          resources:
          - "space:logs"

  roleMappings:
    enabled: false
    list:
    - name: "logs_reader_mapping"
      definition:
        enabled: true
        roles:
        - "logs_reader"
        rules:
          field:
            groups: "cn=log-readers,ou=groups,dc=Techsecom,dc=com"
        metadata:
          description: "Maps LDAP log-readers group to logs_reader role"
    - name: "logs_admin_mapping"
      definition:
        enabled: true
        roles:
        - "logs_admin"
        rules:
          field:
            groups: "cn=log-admins,ou=groups,dc=Techsecom,dc=com"
        metadata:
          description: "Maps LDAP log-admins group to logs_admin role"

########################################
# ECK Stack Configuration
########################################
eck-stack:
  elasticPassword: "Techsecoms-@rke2"
  eck-elasticsearch:
    version: 8.19.9
    fullnameOverride: elasticsearch
    auth:
      # disableElasticUser: true
      roles:
      - secretName: elasticsearch-admin
    ingress:
      enabled: true
      className: nginx
      annotations:
        my: annotation
        kubernetes.io/ingress.class: nginx
        nginx.ingress.kubernetes.io/force-ssl-redirect: "true"
        nginx.ingress.kubernetes.io/ssl-passthrough: "true"
        cert-manager.io/cluster-issuer: letsencrypt-prod
        nginx.ingress.kubernetes.io/ssl-redirect: "true"
      labels:
        my: label
      pathType: Prefix
      hosts:
      - host: "elasticsearch.ops.techsecom.io"
        path: "/"
    http:
      tls:
        selfSignedCertificate:
          disabled: true
        certificate:
          secretName: elasticsearch-es-cert
    nodeSets:
    - name: masters
      count: 3
      config:
        node.roles: [ "master", "remote_cluster_client" ]
        node.store.allow_mmap: false
        # xpack.security.enabled: true
        # xpack.security.transport.ssl.enabled: true
        # xpack.security.http.ssl.enabled: true
        # xpack.monitoring.enabled: false
        xpack.graph.enabled: false
        xpack.watcher.enabled: false
        xpack.security.enrollment.enabled: true
        # xpack.ml.enabled: false
      podTemplate:
        metadata:
          annotations:
            # Disable Stakater Reloader - ECK manages its own config updates
            reloader.stakater.com/auto: "false"
        spec:
          containers:
          - name: elasticsearch
            resources:
              # ECK requires memory request = limit for ResourcesAwareManagement
              limits:
                memory: 2Gi
                cpu: 2
              requests:
                memory: 2Gi
                cpu: 2
            volumeMounts:
            - name: certs
              mountPath: /usr/share/elasticsearch/config/certs
              readOnly: true
          volumes:
          - name: certs
            secret:
              secretName: elasticsearch-es-cert
          securityContext:
            runAsUser: 1000
            fsGroup: 1000
      volumeClaimTemplates:
      - metadata:
          name: elasticsearch-data
        spec:
          accessModes:
          - ReadWriteOnce
          resources:
            requests:
              storage: 15Gi
          storageClassName: longhorn

    - name: hot
      count: 3
      config:
        node.roles: [ "data_hot", "data_content", "ingest", "remote_cluster_client" ]
        node.store.allow_mmap: false
        # xpack.security.enabled: true
        # xpack.security.transport.ssl.enabled: true
        # xpack.security.http.ssl.enabled: true
        # xpack.monitoring.enabled: false
        xpack.graph.enabled: false
        xpack.watcher.enabled: false
        xpack.security.enrollment.enabled: true
        # xpack.ml.enabled: false
        node.attr.data: hot
        node.attr.box_type: hot
      podTemplate:
        metadata:
          annotations:
            # Disable Stakater Reloader - ECK manages its own config updates
            reloader.stakater.com/auto: "false"
        spec:
          containers:
          - name: elasticsearch
            resources:
              # ECK requires memory request = limit for ResourcesAwareManagement
              limits:
                memory: 3Gi
                cpu: 2
              requests:
                memory: 3Gi
                cpu: 2
            volumeMounts:
            - name: certs
              mountPath: /usr/share/elasticsearch/config/certs
              readOnly: true
          volumes:
          - name: certs
            secret:
              secretName: elasticsearch-es-cert
          securityContext:
            runAsUser: 1000
            fsGroup: 1000
      volumeClaimTemplates:
      - metadata:
          name: elasticsearch-data
        spec:
          accessModes:
          - ReadWriteOnce
          resources:
            requests:
              storage: 15Gi
          storageClassName: longhorn
    - name: warm
      count: 3
      config:
        node.roles: [ "data_warm", "remote_cluster_client" ]
        node.store.allow_mmap: false
        # xpack.security.enabled: true
        # xpack.security.transport.ssl.enabled: true
        # xpack.security.http.ssl.enabled: true
        # xpack.monitoring.enabled: false
        xpack.graph.enabled: false
        xpack.watcher.enabled: false
        xpack.security.enrollment.enabled: true
        # xpack.ml.enabled: false
        node.attr.data: warm
        node.attr.box_type: warm
      podTemplate:
        metadata:
          annotations:
            # Disable Stakater Reloader - ECK manages its own config updates
            reloader.stakater.com/auto: "false"
        spec:
          containers:
          - name: elasticsearch
            resources:
              # ECK requires memory request = limit for ResourcesAwareManagement
              limits:
                memory: 3Gi
                cpu: 2
              requests:
                memory: 3Gi
                cpu: 2
            volumeMounts:
            - name: certs
              mountPath: /usr/share/elasticsearch/config/certs
              readOnly: true
          volumes:
          - name: certs
            secret:
              secretName: elasticsearch-es-cert
          securityContext:
            runAsUser: 1000
            fsGroup: 1000
      volumeClaimTemplates:
      - metadata:
          name: elasticsearch-data
        spec:
          accessModes:
          - ReadWriteOnce
          resources:
            requests:
              storage: 10Gi
          storageClassName: longhorn
    - name: cold
      count: 3
      config:
        node.roles: [ "data_cold", "remote_cluster_client" ]
        node.store.allow_mmap: false
        # xpack.security.enabled: true
        # xpack.security.transport.ssl.enabled: true
        # xpack.security.http.ssl.enabled: true
        # xpack.monitoring.enabled: false
        xpack.security.enrollment.enabled: true
        xpack.graph.enabled: false
        xpack.watcher.enabled: false
        # xpack.ml.enabled: false
        node.attr.data: cold
        node.attr.box_type: cold
      podTemplate:
        metadata:
          annotations:
            # Disable Stakater Reloader - ECK manages its own config updates
            reloader.stakater.com/auto: "false"
        spec:
          containers:
          - name: elasticsearch
            resources:
              # ECK requires memory request = limit for ResourcesAwareManagement
              limits:
                memory: 3Gi
                cpu: 2
              requests:
                memory: 3Gi
                cpu: 2
            volumeMounts:
            - name: certs
              mountPath: /usr/share/elasticsearch/config/certs
              readOnly: true
          volumes:
          - name: certs
            secret:
              secretName: elasticsearch-es-cert
          securityContext:
            runAsUser: 1000
            fsGroup: 1000
      volumeClaimTemplates:
      - metadata:
          name: elasticsearch-data
        spec:
          accessModes:
          - ReadWriteOnce
          resources:
            requests:
              storage: 20Gi
          storageClassName: longhorn
  eck-kibana:
    enabled: true
    version: 8.19.9
    # Name of the Kibana instance.
    #
    fullnameOverride: kibana

    spec:
      count: 1
      elasticsearchRef:
        name: elasticsearch

      config:
        elasticsearch.requestHeadersWhitelist:
        - authorization
        server.publicBaseUrl: https://kibana.ops.techsecom.io
      http:
        tls:
          certificate:
            secretName: elasticsearch-es-cert # Use the cert-manager generated secret

      podTemplate:
        metadata:
          labels:
            scrape: kob-r1-lab-kb
          annotations:
            # Disable Stakater Reloader - ECK manages its own config updates
            reloader.stakater.com/auto: "false"
        spec:
          containers:
          - name: kibana
            resources:
              # CPU must be multiples of 2 due to SMT alignment on your nodes
              requests:
                memory: 1Gi
                cpu: 2
              limits:
                memory: 2Gi
                cpu: 2
            env:
            - name: NODE_OPTIONS
              value: "--max-old-space-size=2048"
            - name: SERVER_PUBLICBASEURL
              value: "https://kibana.ops.techsecom.io"

            volumeMounts:
            - name: certs
              mountPath: /usr/share/kibana/config/certs
              readOnly: true
          volumes:
          - name: certs
            secret:
              secretName: elasticsearch-es-cert

    ingress:
      enabled: true
      className: nginx
      annotations:
        nginx.ingress.kubernetes.io/backend-protocol: HTTPS
        nginx.ingress.kubernetes.io/proxy-body-size: 20m
        cert-manager.io/cluster-issuer: letsencrypt-prod
      pathType: Prefix
      hosts:
      - host: "kibana.ops.techsecom.io"
        path: "/"
      tls:
        enabled: true
        secretName: kibana-tls
  eck-beats:
    enabled: true
    version: 8.19.9
    spec:
      type: filebeat
      # daemonSet:
      daemonSet:
        podTemplate:
          # Metadata so that Metricbeat can scrape metrics from these pods
          metadata:
            labels:
              scrape: kob-r1-lab-fb
            annotations:
              # Disable Stakater Reloader - ECK manages its own config updates
              reloader.stakater.com/auto: "false"
          spec:
            serviceAccountName: filebeat
            automountServiceAccountToken: true
            terminationGracePeriodSeconds: 30
            dnsPolicy: ClusterFirstWithHostNet
            tolerations:
            - effect: NoSchedule
              key: node-role.kubernetes.io/control-plane
              operator: Exists
            - effect: NoSchedule
              key: node-role.kubernetes.io/master
              operator: Exists
            # hostNetwork: true
            containers:
            - name: filebeat
              resources:
                # CPU must be multiples of 2 due to SMT alignment on your nodes
                limits:
                  memory: 8Gi
                  cpu: 4
                requests:
                  cpu: 4
                  memory: 4Gi
              securityContext:
                runAsUser: 0
              volumeMounts:
              - name: varlogcontainers
                mountPath: /var/log/containers
              - name: auditlog
                mountPath: /var/log/rancher
              - name: varlogpods
                mountPath: /var/log/pods
              env:
              - name: NODE_NAME
                valueFrom:
                  fieldRef:
                    fieldPath: spec.nodeName
            volumes:
            - name: varlogcontainers
              hostPath:
                path: /var/log/containers
            - name: varlogpods
              hostPath:
                path: /var/log/pods
            - name: auditlog
              hostPath:
                path: /var/log/rancher
            - name: data
              emptydir: {}
            - name: beat-data
              emptydir: {}
      config:
        http.enabled: true
        http.host: 0.0.0.0
        http.port: 5066
        # queue.mem:
        #   events: 2048
        #   flush.min_events: 50
        #   flush.timeout: 5s
        enabled: true
        filebeat.autodiscover:
          providers:
          - type: kubernetes
            hints.enabled: true
            include_labels: [ "app.kubernetes.io/name" ]
            labels.dedot: true
            node: ${NODE_NAME}
            hints.default_config:
              type: container
              paths:
              - /var/log/containers/*-${data.container.id}.log
              exclude_lines: [ "^\\s+[\\-`('.|_]" ]
              processors:
              - add_kubernetes_metadata:
                  host: ${NODE_NAME}
                  matchers:
                  - logs_path:
                      logs_path: "/var/log/containers/"
        filebeat.inputs:
        - type: filestream
          id: audit-logs
          enabled: true
          # max_bytes: "1048576"
          paths:
          - /var/log/rancher/*.log
          scan_frequency: 10s
          json.keys_under_root: true
          json.add_error_key: true
          tags: [ "audit" ]
          tail_files: true
          parsers:
          - multiline:
              type: pattern
              pattern: "^[0-9]{4}-[0-9]{2}-[0-9]{2}"
              negate: false
              match: after
              max_lines: 1000
              timeout: 5s
        filebeat.config.modules:
          path: ${path.config}/modules.d/*.yml
          reload.enabled: true
          reload.period: 10s
        setup.template.settings:
          index.number_of_shards: 1
        processors:
        - add_host_metadata: {}
        - add_cloud_metadata: {}
        output.logstash:
          # This needs to be {{logstash-name}}-ls-beats:5044
          hosts: [ "eck-stack-eck-logstash-ls-beats.elastic-system.svc:5044" ]
      # deployment: null

  eck-logstash:
    enabled: true
    version: 8.19.9
    config:
      log.level: info
      queue.type: persisted
      path.queue: /usr/share/logstash/dp
      dead_letter_queue.max_bytes: 10gb
      # pipeline.buffer.type: heap

    podTemplate:
      metadata:
        annotations:
          # Disable Stakater Reloader - ECK manages its own config updates
          reloader.stakater.com/auto: "false"
      spec:
        # Override init container resources to fix SMT alignment error
        # Your nodes require CPU requests to be multiples of 2 (SMT cores per physical core)
        initContainers:
        - name: logstash-internal-init-config
          resources:
            requests:
              cpu: 2
              memory: 128Mi
            limits:
              cpu: 2
              memory: 256Mi
        - name: elastic-internal-init-keystore
          resources:
            requests:
              cpu: 2
              memory: 1Gi
            limits:
              cpu: 2
              memory: 2Gi
        containers:
        - name: logstash
          resources:
            requests:
              memory: 2Gi
              cpu: 2
            limits:
              memory: 4Gi
              cpu: 2
          env:
          - name: ES_USER
            value: "elastic"
          - name: ES_PASSWORD
            valueFrom:
              secretKeyRef:
                name: elasticsearch-es-elastic-user
                key: elastic
          # - name: LS_JAVA_OPTS
          #   value: "-Xms3g -Xmx3g -Dio.netty.allocator.maxOrder=13"
          volumeMounts:
          - mountPath: /usr/share/logstash/pq
            name: pq
            readOnly: false
          - mountPath: /usr/share/logstash/dlq
            name: dlq
            readOnly: false
          - mountPath: /etc/logstash/config/certs
            name: certs
            readOnly: true
        volumes:
        - name: certs
          secret:
            secretName: elasticsearch-es-cert
    pipelines:
    - pipeline.id: main
      dead_letter_queue.enable: true
      path.dead_letter_queue: /usr/share/logstash/dlq
      config.reload.automatic: true
      config.reload.interval: 30s
      # dead_letter_queue.max_bytes: 5333mb
      dead_letter_queue.storage_policy: drop_older
      dead_letter_queue.max_bytes: 5gb
      dead_letter_queue.retain.age: 10m
      pipeline.ecs_compatibility: disabled
      # pipeline.workers: 1
      config.string: |
        input {
          beats {
            port => 5044
          }
        }

        filter {
          if "audit" in [tags] {
            json {
              source => "message"
              target => "auditdata"
              skip_on_invalid_json => true
              remove_field => [ "[auditdata][annotations]", "[auditdata][apiVersion]", "[auditdata][kind]", "[auditdata][level]", "[auditdata][responseStatus][message]", "[auditdata][stage]", "[auditdata][stageTimestamp]", "[auditdata][userAgent]" ]
            }
            mutate {
              add_field => { "[@metadata][target_index]" => "audit-logs" }
            }
          } else if "audit" not in [tags] {
            grok {
              match => { "message" => "%{SYSLOG5424LINE}" }
            }
            if [syslog5424_sd] {
              mutate {
                gsub => [ "syslog5424_sd", "[\[\]]", "" ]
              }
              kv {
                source => "syslog5424_sd"
                field_split => " "
                value_split => "="
                target => "kv_data"
                remove_field => [ "syslog5424_sd" ]
              }
            }
            ruby {
              code => '
                event.to_hash.each { |k, v|
                  event.remove(k)
                  newE = k.sub(/app\..*\/(\w+)/, "k8_\\1")
                  event.set(newE, v)
                }
              '
            }
            if [istio.io/rev] {
              mutate {
                rename => { "istio.io/rev" =>  "istio_k8_rev" }
              }
            }
            if [kubernetes] {
              mutate {
                add_field => {
                  "container_name" => "%{[kubernetes][container][name]}"
                  "namespace" => "%{[kubernetes][namespace]}"
                  "pod" => "%{[kubernetes][pod][name]}"
                }
                replace => { "host" => "%{[kubernetes][node][name]}" }
              }
            }
            mutate {
              add_field => { "[@metadata][target_index]" => "container-logs" }
            }
          }
        }

        output {
          if [@metadata][target_index] == "container-logs" {
              elasticsearch {
              hosts => [ "https://elasticsearch-es-http.elastic-system.svc:9200" ]
              user => "${ES_USER}"
              password => "${ES_PASSWORD}"
              ilm_rollover_alias => "container-logs"
              ilm_pattern => "000001"
              ilm_enabled => true
              ilm_policy => "hot_warm_delete-container-logs"
              data_stream => auto
              ssl_enabled => true
              ssl_certificate_authorities => ["/etc/logstash/config/certs/ca.crt"]
            }
          } else if [@metadata][target_index] == "audit-logs" {
            elasticsearch {
              hosts => [ "https://elasticsearch-es-http.elastic-system.svc:9200" ]
              user => "${ES_USER}"
              password => "${ES_PASSWORD}"
              ilm_enabled => true
              ilm_rollover_alias => "audit-logs"
              ilm_pattern => "000001"
              ilm_policy => "hot_warm_delete-audit-logs"
              ssl_enabled => true
              data_stream => auto
              ssl_certificate_authorities => ["/etc/logstash/config/certs/ca.crt"]
            }
          }
        }
    volumeClaimTemplates:
    - metadata:
        name: pq
      spec:
        accessModes:
        - ReadWriteOnce
        resources:
          requests:
            storage: 15Gi
    - metadata:
        name: dlq
      spec:
        accessModes:
        - ReadWriteOnce
        resources:
          requests:
            storage: 20Gi

    elasticsearchRefs:
    - clusterName: eck
      name: elasticsearch
    secureSettings:
    - secretName: elasticsearch-es-cert
    services:
    - name: beats
      service:
        spec:
          type: ClusterIP
          ports:
          - port: 5044
            name: "filebeat"
            protocol: TCP
            targetPort: 5044
