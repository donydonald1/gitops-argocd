# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Rancher Monitoring (Prometheus, Alertmanager, Grafana)
# This chart integrates with Rancher UI for cluster monitoring visibility
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
rancher-monitoring:
  fullnameOverride: "rancher-monitoring"
  nameOverride: "rancher-monitoring"
  namespaceOverride: "cattle-monitoring-system"

  # Global settings for Rancher integration
  global:
    cattle:
      clusterId: local
      clusterName: ops-dc-tx-rke2-mgmt-prod
      systemDefaultRegistry: ""
      windows:
        enabled: false
    rbac:
      create: true
      userRoles:
        create: true
        aggregateToDefaultRoles: true

  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  # Grafana Configuration
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  grafana:
    enabled: true

    env:
      GF_SERVER_ROOT_URL: https://grafana.ops.techsecom.io
      GF_SECURITY_COOKIE_SAMESITE: grafana
      TZ: America/Chicago
      GF_DATABASE_TYPE: postgres
      GF_DATABASE_HOST: cnpg-cluster-rw.cnpg-system.svc.cluster.local:5432
      GF_DATABASE_NAME: grafana
      GF_DATABASE_SSL_MODE: disable

    admin:
      existingSecret: grafana-admin-creds
      userKey: username
      passwordKey: password

    plugins:
      - grafana-exploretraces-app

    assertNoLeakedSecrets: false
    initChownData:
      enabled: false

    persistence:
      enabled: true
      type: statefulset
      storageClassName: longhorn
      accessModes:
        - ReadWriteOnce
      size: 10Gi

    service:
      type: ClusterIP
      port: 80
      nodePort: 30950

    grafana.ini:
      server:
        root_url: https://grafana.ops.techsecom.io
      auth.anonymous:
        org_name: "Techsecom Consulting Group"
      dataproxy:
        max_idle_connections: 500
      security:
        allow_embedding: true
      feature_toggles:
        provisioning: true
        kubernetesDashboards: true
      auth:
        auto_login: true
        disable_signout_menu: false
      auth.generic_oauth:
        enabled: true
        client_id: <path:secret/data/grafana#client_id>
        client_secret: <path:secret/data/grafana#client_secret>
        allow_sign_up: true
        scopes: openid profile email roles
        auth_url: <path:secret/data/grafana#auth_url>
        token_url: <path:secret/data/grafana#token_url>
        api_url: <path:secret/data/grafana#api_url>
        use_pkce: true
        use_refresh_token: true
      users:
        auto_assign_org: true
        auto_assign_org_role: Editor
      auth.basic:
        enabled: false
      dashboards:
        default_home_dashboard_path: /tmp/dashboards/rancher-default-home.json
      database:
        type: postgres
        host: "cnpg-cluster-rw.cnpg-system.svc.cluster.local:5432"
        name: grafana
        user: $__file{/etc/secrets/username}
        password: $__file{/etc/secrets/password}
        ssl_mode: disable
      plugins:
        allow_loading_unsigned_plugins: grafana-pyroscope-app,grafana-exploretraces-app

    extraSecretMounts:
      - name: grafana-db-secret
        secretName: grafana-user-secret
        mountPath: /etc/secrets
        readOnly: true

    extraEnvFrom:
      - secretRef:
          name: grafana-user-secret

    extraEnv:
      - name: GF_DATABASE_USER
        valueFrom:
          secretKeyRef:
            name: grafana-user-secret
            key: username
      - name: GF_DATABASE_PASSWORD__FILE
        value: /etc/secrets/password

    ingress:
      enabled: true
      ingressClassName: nginx
      annotations:
        kubernetes.io/ingress.class: "nginx"
        cert-manager.io/cluster-issuer: "letsencrypt-prod"
        cert-manager.io/revision-history-limit: "3"
        external-dns.alpha.kubernetes.io/enabled: "true"
        cert-manager.io/duration: "2160h"
        cert-manager.io/renew-before: "720h"
      hosts:
        - grafana.ops.techsecom.io
      tls:
        - hosts:
            - grafana.ops.techsecom.io
          secretName: grafana-cert-tls

    serviceMonitor:
      enabled: true

    serviceAccount:
      autoMount: true
      create: true

    sidecar:
      dashboards:
        enabled: true
        label: grafana_dashboard
        labelValue: "1"
        searchNamespace: cattle-dashboards
        provider:
          allowUiUpdates: false
      datasources:
        enabled: true
        defaultDatasourceEnabled: true
        label: grafana_datasource
        labelValue: "1"
        alertmanager:
          enabled: true
          name: Alertmanager
          uid: alertmanager

    # Rancher-specific defaults
    defaultDashboards:
      cleanupOnUninstall: false
      namespace: cattle-dashboards
      useExistingNamespace: false
    defaultDashboardsEditable: true
    defaultDashboardsEnabled: true
    defaultDashboardsTimezone: utc

    resources:
      limits:
        cpu: 200m
        memory: 200Mi
      requests:
        cpu: 100m
        memory: 100Mi

    # Additional datasources for Thanos, Loki, Tempo
    additionalDataSources:
      - name: Thanos
        uid: thanos
        type: prometheus
        access: proxy
        url: http://clover-monitoring-thanos-query.cattle-monitoring-system.svc.cluster.local:9090
        isDefault: false
        jsonData:
          httpMethod: POST
          exemplarTraceIdDestinations:
            - datasourceUid: tempo
              name: Tempo
        editable: false

      - name: Loki
        uid: loki
        type: loki
        access: proxy
        url: http://clover-monitoring-loki-gateway.cattle-monitoring-system.svc.cluster.local
        isDefault: false
        jsonData:
          httpHeaderName1: "X-scope-OrgID"
          derivedFields:
            - name: trace_id
              matcherRegex: '"trace_id"\\s*:\\s*"([a-fA-F0-9\\-]+)"'
              datasourceUid: tempo
              internalLink: true
            - name: traceId
              matcherRegex: '"traceId"\\s*:\\s*"([a-fA-F0-9\\-]+)"'
              datasourceUid: tempo
              internalLink: true
        editable: false

      - name: Tempo
        uid: tempo
        type: tempo
        access: proxy
        url: http://tempo.cattle-monitoring-system.svc.cluster.local:3200
        isDefault: false
        jsonData:
          httpMethod: GET
          tracesToLogsV2:
            datasourceUid: loki
          search:
            hide: false
          lokiSearch:
            datasourceUid: loki
          tracesToLogs:
            datasourceUid: loki
            mapTagNamesEnabled: true
            tags: ["namespace", "pod", "container", "audit", "app"]
            filterByTraceID: true
            filterBySpanID: true
          serviceMap:
            datasourceUid: thanos
          nodeGraph:
            enabled: true
        editable: false

  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  # Prometheus Configuration
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  prometheus:
    enabled: true

    thanosService:
      enabled: true

    service:
      type: ClusterIP
      port: 9090
      nodePort: 30090

    ingress:
      enabled: true
      pathType: Prefix
      ingressClassName: nginx
      annotations:
        kubernetes.io/ingress.class: "nginx"
        cert-manager.io/cluster-issuer: letsencrypt-prod
        cert-manager.io/revision-history-limit: "3"
        external-dns.alpha.kubernetes.io/enabled: "true"
        cert-manager.io/duration: "2160h"
        cert-manager.io/renew-before: "720h"
      hosts:
        - prometheus.ops.techsecom.io
      tls:
        - hosts:
            - prometheus.ops.techsecom.io
          secretName: prom-server-cert-tls

    prometheusSpec:
      externalLabels:
        cluster: "ops-dc-tx-rke2-mgmt-prod"

      # Thanos sidecar for long-term storage
      thanos:
        image: rancher/mirrored-thanos-thanos:v0.39.2
        version: "v0.39.2"

      enableFeatures:
        - auto-gomemlimit
        - memory-snapshot-on-shutdown
        - new-service-discovery-manager
        - exemplar-storage
        - native-histograms

      # Pick up all ServiceMonitors/PodMonitors across namespaces
      serviceMonitorSelectorNilUsesHelmValues: false
      podMonitorSelectorNilUsesHelmValues: false
      ruleSelectorNilUsesHelmValues: false
      scrapeConfigSelectorNilUsesHelmValues: false

      enableRemoteWriteReceiver: true
      enableAdminAPI: true
      replicas: 1

      scrapeInterval: 30s
      evaluationInterval: 30s
      retention: 10d
      retentionSize: 50GiB

      resources:
        limits:
          cpu: 1000m
          memory: 3000Mi
        requests:
          cpu: 750m
          memory: 750Mi

      storageSpec:
        volumeClaimTemplate:
          spec:
            accessModes:
              - ReadWriteOnce
            resources:
              requests:
                storage: 50Gi
            storageClassName: longhorn

      securityContext:
        fsGroup: 2000
        runAsGroup: 2000
        runAsNonRoot: true
        runAsUser: 1000
        seccompProfile:
          type: RuntimeDefault

      additionalScrapeConfigs:
        - job_name: prometheus
          static_configs:
            - targets:
                - localhost:9090
        - job_name: kubernetes-apiservers
          kubernetes_sd_configs:
            - role: endpoints
          scheme: https
          tls_config:
            ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
            insecure_skip_verify: true
          bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
          relabel_configs:
            - source_labels: [__meta_kubernetes_namespace, __meta_kubernetes_service_name, __meta_kubernetes_endpoint_port_name]
              action: keep
              regex: default;kubernetes;https

    serviceMonitor:
      selfMonitor: true

  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  # Alertmanager Configuration
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  alertmanager:
    enabled: true

    config:
      global:
        resolve_timeout: 5m
      route:
        group_by: ['alertname', 'job']
        group_wait: 45s
        group_interval: 10m
        repeat_interval: 12h
        receiver: "msteams"
        routes:
          - receiver: "null"
            matchers:
              - alertname =~ "Watchdog"
          - receiver: "null"
            matchers:
              - alertname =~ "InfoInhibitor"
          - receiver: "msteams"
            match:
              severity: critical
            continue: true
          - receiver: "msteams"
      inhibit_rules:
        - source_matchers:
            - severity = "critical"
          target_matchers:
            - severity = "warning"
          equal: ["alertname", "namespace"]
        - target_match_re:
            alertname: '.+Overcommit'
          source_match:
            alertname: 'Watchdog'
          equal: ['prometheus']
      receivers:
        - name: "null"
        - name: "msteams"
          msteams_configs:
            - send_resolved: true
              webhook_url: <path:secret/data/msteams#webhook-url>
              title: |-
                ðŸš¨ [{{ .Status | toUpper }}{{ if eq .Status "firing" }}:{{ .Alerts.Firing | len }}{{ end }}]
                (Cluster: {{ .CommonLabels.cluster }})

                **ðŸ“¢ Alert Notification - Techsecoms Monitoring**

                {{ if eq .Status "firing" }}ðŸ”¥ **Action Required Immediately!** ðŸ”¥{{ else }}âœ… **Issue Resolved** âœ…{{ end }}

              text: |-
                **ðŸ”” Alert Details:**
                {{ range $index, $alert := .Alerts -}}{{ if $index }}---{{ end }}
                {{ if $alert.Labels.alertname }}
                **ðŸ†˜ Alert Name**: {{ $alert.Labels.alertname }}
                {{ end }}

                **ðŸ›‘ Labels:**
                {{ if $alert.Labels.severity }}
                - **Severity**: {{ $alert.Labels.severity }}
                {{ end }}
                {{ if $alert.Labels.instance }}
                - **Instance**: {{ $alert.Labels.instance }}
                {{ end }}
                {{ if $alert.Labels.namespace }}
                - **Namespace**: {{ $alert.Labels.namespace }}
                {{ end }}
                {{ if $alert.Labels.pod }}
                - **Pod**: {{ $alert.Labels.pod }}
                {{ end }}

                **ðŸ“„ Annotations:**
                {{ if $alert.Annotations.description }}
                - **Description**: {{ $alert.Annotations.description }}
                {{ end }}
                {{ if $alert.Annotations.summary }}
                - **Summary**: {{ $alert.Annotations.summary }}
                {{ end }}

                {{ if $alert.GeneratorURL }}
                ðŸ”— **Source**: [View in AlertManager]({{ $alert.GeneratorURL }})
                {{ end }}

                **ðŸ“Œ Additional Notes:**
                - Ensure the affected service is reviewed immediately.
                - Escalate to the **on-call team** if required.
                - Check related metrics and logs for further debugging.

                {{ end }}

    alertmanagerSpec:
      replicas: 1
      retention: 120h
      externalUrl: https://alertmanager.ops.techsecom.io

      storage:
        volumeClaimTemplate:
          spec:
            storageClassName: longhorn
            resources:
              requests:
                storage: 10Gi

      resources:
        limits:
          cpu: 1000m
          memory: 500Mi
        requests:
          cpu: 100m
          memory: 100Mi

      securityContext:
        fsGroup: 2000
        runAsGroup: 2000
        runAsNonRoot: true
        runAsUser: 1000
        seccompProfile:
          type: RuntimeDefault

    serviceMonitor:
      selfMonitor: true

    templateFiles:
      rancher_defaults.tmpl: >-
        {{- define "slack.rancher.text" -}}
        {{ template "rancher.text_multiple" . }}
        {{- end -}}

        {{- define "rancher.text_multiple" -}}
        *[GROUP - Details]*
        One or more alarms in this group have triggered a notification.

        {{- if gt (len .GroupLabels.Values) 0 }}
        *Group Labels:*
          {{- range .GroupLabels.SortedPairs }}
          â€¢ *{{ .Name }}:* `{{ .Value }}`
          {{- end }}
        {{- end }}
        {{- if .ExternalURL }}
        *Link to AlertManager:* {{ .ExternalURL }}
        {{- end }}

        {{- range .Alerts }}
        {{ template "rancher.text_single" . }}
        {{- end }}
        {{- end -}}

        {{- define "rancher.text_single" -}}
        {{- if .Labels.alertname }}
        *[ALERT - {{ .Labels.alertname }}]*
        {{- else }}
        *[ALERT]*
        {{- end }}
        {{- if .Labels.severity }}
        *Severity:* `{{ .Labels.severity }}`
        {{- end }}
        {{- if .Labels.cluster }}
        *Cluster:*  {{ .Labels.cluster }}
        {{- end }}
        {{- if .Annotations.summary }}
        *Summary:* {{ .Annotations.summary }}
        {{- end }}
        {{- if .Annotations.message }}
        *Message:* {{ .Annotations.message }}
        {{- end }}
        {{- if .Annotations.description }}
        *Description:* {{ .Annotations.description }}
        {{- end }}
        {{- if .Annotations.runbook_url }}
        *Runbook URL:* <{{ .Annotations.runbook_url }}|:spiral_note_pad:>
        {{- end }}
        {{- with .Labels }}
        {{- with .Remove (stringSlice "alertname" "severity" "cluster") }}
        {{- if gt (len .) 0 }}
        *Additional Labels:*
          {{- range .SortedPairs }}
          â€¢ *{{ .Name }}:* `{{ .Value }}`
          {{- end }}
        {{- end }}
        {{- end }}
        {{- end }}
        {{- with .Annotations }}
        {{- with .Remove (stringSlice "summary" "message" "description" "runbook_url") }}
        {{- if gt (len .) 0 }}
        *Additional Annotations:*
          {{- range .SortedPairs }}
          â€¢ *{{ .Name }}:* `{{ .Value }}`
          {{- end }}
        {{- end }}
        {{- end }}
        {{- end }}
        {{- end -}}

  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  # Prometheus Operator Configuration
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  prometheusOperator:
    enabled: true

    admissionWebhooks:
      enabled: true
      patch:
        enabled: true

    serviceMonitor:
      selfMonitor: true

  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  # Node Exporter
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  nodeExporter:
    enabled: true

  prometheus-node-exporter:
    prometheus:
      monitor:
        enabled: true

  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  # Kube State Metrics
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  kubeStateMetrics:
    enabled: true

  kube-state-metrics:
    prometheus:
      monitor:
        enabled: true
        honorLabels: true

  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  # RKE2 Component Monitoring
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  rke2ControllerManager:
    enabled: true
    clients:
      https:
        enabled: true
        insecureSkipVerify: true
        useServiceAccountCredentials: true
      nodeSelector:
        node-role.kubernetes.io/master: 'true'
      port: 10011
      tolerations:
        - effect: NoExecute
          operator: Exists
        - effect: NoSchedule
          operator: Exists
      useLocalhost: true
    component: kube-controller-manager
    metricsPort: 10257

  rke2Etcd:
    enabled: true
    clients:
      nodeSelector:
        node-role.kubernetes.io/etcd: 'true'
      port: 10014
      tolerations:
        - effect: NoExecute
          operator: Exists
        - effect: NoSchedule
          operator: Exists
      useLocalhost: true
    component: kube-etcd
    metricsPort: 2381

  rke2Proxy:
    enabled: true
    clients:
      port: 10013
      tolerations:
        - effect: NoExecute
          operator: Exists
        - effect: NoSchedule
          operator: Exists
      useLocalhost: true
    component: kube-proxy
    metricsPort: 10249

  rke2Scheduler:
    enabled: true
    clients:
      https:
        enabled: true
        insecureSkipVerify: true
        useServiceAccountCredentials: true
      nodeSelector:
        node-role.kubernetes.io/master: 'true'
      port: 10012
      tolerations:
        - effect: NoExecute
          operator: Exists
        - effect: NoSchedule
          operator: Exists
      useLocalhost: true
    component: kube-scheduler
    metricsPort: 10259

  rke2IngressNginx:
    enabled: true
    clients:
      enabled: false
    component: ingress-nginx
    metricsPort: 10254
    namespaceOverride: kube-system
    service:
      selector:
        app.kubernetes.io/name: rke2-ingress-nginx

  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  # Disable non-RKE2 components
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  kubeControllerManager:
    enabled: false
  kubeScheduler:
    enabled: false
  kubeProxy:
    enabled: false
  kubeEtcd:
    enabled: false
  kubeDns:
    enabled: false

  # Enable API server monitoring
  kubeApiServer:
    enabled: true

  # Enable kubelet monitoring
  kubelet:
    enabled: true
    namespace: kube-system

  # Enable CoreDNS monitoring
  coreDns:
    enabled: true

  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  # Default Rules
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  defaultRules:
    create: true
    rules:
      alertmanager: true
      etcd: true
      configReloaders: true
      general: true
      k8sContainerCpuUsageSecondsTotal: true
      k8sContainerMemoryCache: true
      k8sContainerMemoryRss: true
      k8sContainerMemorySwap: true
      k8sContainerMemoryWorkingSetBytes: true
      k8sContainerResource: true
      k8sPodOwner: true
      kubeApiserverAvailability: true
      kubeApiserverBurnrate: true
      kubeApiserverHistogram: true
      kubeApiserverSlos: true
      kubeControllerManager: true
      kubePrometheusGeneral: true
      kubePrometheusNodeRecording: true
      kubeProxy: true
      kubeSchedulerAlerting: true
      kubeSchedulerRecording: true
      kubeStateMetrics: true
      kubelet: true
      kubernetesApps: true
      kubernetesResources: true
      kubernetesStorage: true
      kubernetesSystem: true
      network: true
      node: true
      nodeExporterAlerting: true
      nodeExporterRecording: true
      prometheus: true
      prometheusOperator: true

  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  # Rancher Monitoring Integration
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  rancherMonitoring:
    enabled: true
    namespaceSelector:
      matchNames:
        - cattle-system

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Bitnami Thanos (Query, Store Gateway, Compactor)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
thanos:
  image:
    registry: quay.io
    repository: thanos/thanos
    tag: v0.37.2

  query:
    enabled: true
    replicaCount: 2
    replicaLabels:
      - replica
    dnsDiscovery:
      sidecarsService: rancher-monitoring-thanos-discovery
      sidecarsNamespace: cattle-monitoring-system
    ingress:
      enabled: true
      hostname: thanos.ops.techsecom.io
      annotations:
        kubernetes.io/ingress.class: "nginx"
        cert-manager.io/cluster-issuer: "letsencrypt-prod"
        cert-manager.io/revision-history-limit: "3"
        external-dns.alpha.kubernetes.io/enabled: "true"
        cert-manager.io/duration: "2160h"
        cert-manager.io/renew-before: "720h"
      tls: true

  queryFrontend:
    enabled: true

  bucketweb:
    enabled: true
    ingress:
      enabled: true
      hostname: thanos-bucketweb.ops.techsecom.io
      annotations:
        kubernetes.io/ingress.class: "nginx"
        cert-manager.io/cluster-issuer: letsencrypt-prod
        cert-manager.io/revision-history-limit: "3"
        external-dns.alpha.kubernetes.io/enabled: "true"
        cert-manager.io/duration: "2160h"
        cert-manager.io/renew-before: "720h"
      tls: true

  compactor:
    enabled: true
    retentionResolutionRaw: 7d
    retentionResolution5m: 14d
    retentionResolution1h: 30d
    ingress:
      enabled: true
      hostname: thanos-compactor.ops.techsecom.io
      annotations:
        kubernetes.io/ingress.class: "nginx"
        cert-manager.io/cluster-issuer: letsencrypt-prod
        cert-manager.io/revision-history-limit: "3"
        external-dns.alpha.kubernetes.io/enabled: "true"
        cert-manager.io/duration: "2160h"
        cert-manager.io/renew-before: "720h"
      tls: true
    persistence:
      enabled: true
      storageClass: longhorn
      size: 20Gi

  storegateway:
    enabled: true
    ingress:
      enabled: true
      hostname: thanos-storegateway.ops.techsecom.io
      annotations:
        kubernetes.io/ingress.class: "nginx"
        cert-manager.io/cluster-issuer: letsencrypt-prod
        cert-manager.io/revision-history-limit: "3"
        external-dns.alpha.kubernetes.io/enabled: "true"
        cert-manager.io/duration: "2160h"
        cert-manager.io/renew-before: "720h"
      tls: true
    persistence:
      enabled: true
      storageClass: longhorn
      size: 7Gi

  ruler:
    enabled: false

  metrics:
    enabled: true
    serviceMonitor:
      enabled: true

  objstoreConfig: |
    type: s3
    config:
      bucket: thanos
      endpoint: "minio.minio.svc.cluster.local:9000"
      access_key: <path:secret/data/minio#postgres_user>
      secret_key: <path:secret/data/minio#postgres_password>
      insecure: true

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Loki (Log Aggregation)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
loki:
  deploymentMode: SimpleScalable

  loki:
    auth_enabled: false

    analytics:
      reporting_enabled: false

    compactor:
      working_directory: /var/loki/compactor/retention
      delete_request_store: s3
      retention_enabled: true

    frontend:
      max_outstanding_per_tenant: 4096

    ingester:
      chunk_encoding: snappy

    commonConfig:
      replication_factor: 2

    limits_config:
      ingestion_burst_size_mb: 128
      ingestion_rate_mb: 64
      max_query_parallelism: 100
      per_stream_rate_limit: 64M
      per_stream_rate_limit_burst: 128M
      reject_old_samples: true
      reject_old_samples_max_age: 168h
      retention_period: 14d
      shard_streams:
        enabled: true
      split_queries_by_interval: 1h

    query_scheduler:
      max_outstanding_requests_per_tenant: 4096

    rulerConfig:
      enable_api: true
      enable_alertmanager_v2: true
      alertmanager_url: http://rancher-monitoring-alertmanager.cattle-monitoring-system.svc.cluster.local:9093
      storage:
        type: local
        local:
          directory: /rules
      rule_path: /rules/fake

    schemaConfig:
      configs:
        - from: "2024-04-01"
          store: tsdb
          object_store: s3
          schema: v13
          index:
            prefix: loki_index_
            period: 24h

    server:
      log_level: info
      grpc_server_max_recv_msg_size: 8388608
      grpc_server_max_send_msg_size: 8388608

    storage:
      type: s3
      bucketNames:
        chunks: loki-chunks
        ruler: loki-ruler
        admin: loki-admin
      s3:
        s3ForcePathStyle: true
        insecure: true
        endpoint: http://minio.minio.svc.cluster.local:9000
        secretAccessKey: <path:secret/data/minio#postgres_password>
        accessKeyId: <path:secret/data/minio#postgres_user>
        region: us-east-1

  gateway:
    replicas: 2
    enabled: true
    image:
      registry: docker.io
      repository: nginxinc/nginx-unprivileged
      tag: 1.29-alpine
    nginxConfig:
      resolver: "rke2-coredns-rke2-coredns.kube-system.svc.cluster.local valid=30s ipv6=off"

  write:
    replicas: 3
    persistence:
      size: 10Gi
      storageClass: "longhorn"

  read:
    replicas: 2

  backend:
    replicas: 2
    persistence:
      storageClass: "longhorn"

  ingress:
    enabled: true
    ingressClassName: "nginx"
    annotations:
      cert-manager.io/cluster-issuer: "letsencrypt-prod"
      cert-manager.io/revision-history-limit: "3"
      external-dns.alpha.kubernetes.io/enabled: "true"
      cert-manager.io/duration: "2160h"
      cert-manager.io/renew-before: "720h"
    paths:
      distributor:
        - /api/prom/push
        - /loki/api/v1/push
        - /otlp/v1/logs
      queryFrontend:
        - /api/prom/query
        - /api/prom/label
        - /api/prom/series
        - /api/prom/tail
        - /loki/api/v1/query
        - /loki/api/v1/query_range
        - /loki/api/v1/tail
        - /loki/api/v1/label
        - /loki/api/v1/labels
        - /loki/api/v1/series
        - /loki/api/v1/index/stats
    hosts:
      - loki.ops.techsecom.io
    tls:
      - secretName: loki-distributed-tls
        hosts:
          - loki.ops.techsecom.io

  monitoring:
    dashboards:
      enabled: true
      labels:
        grafana_dashboard: "1"
    rules:
      enabled: true
      alerting: true
    serviceMonitor:
      enabled: true
    podMonitor:
      enabled: true

  lokiCanary:
    enabled: false

  test:
    enabled: false

  sidecar:
    image:
      repository: ghcr.io/kiwigrid/k8s-sidecar
    rules:
      searchNamespace: ALL
      folder: /rules/fake

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Tempo (Distributed Tracing)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
tempo:
  enabled: true
  fullnameOverride: tempo

  serviceMonitor:
    enabled: true

  stream_over_http_enabled: true

  gateway:
    enabled: true

  minio:
    enabled: false

  storage:
    trace:
      backend: s3
      s3:
        access_key: <path:secret/data/minio#postgres_user>
        secret_key: <path:secret/data/minio#postgres_password>
        bucket: "tempo-traces"
        endpoint: "http://minio.minio.svc.cluster.local:9000"
        insecure: true

  traces:
    otlp:
      http:
        enabled: true
      grpc:
        enabled: true

  distributor:
    config:
      log_received_spans:
        enabled: true
      log_discarded_spans:
        enabled: true

  tempo:
    metricsGenerator:
      enabled: true
      remoteWriteUrl: "http://rancher-monitoring-prometheus.cattle-monitoring-system.svc.cluster.local:9090/api/v1/write"

  persistence:
    enabled: true
    size: 20Gi
    storageClassName: longhorn

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Promtail (Log Collection)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
promtail:
  enabled: true

  config:
    logLevel: info
    serverPort: 3101
    clients:
      - url: http://clover-monitoring-loki-gateway.cattle-monitoring-system.svc.cluster.local/loki/api/v1/push
        backoff_config:
          min_period: 500ms
          max_period: 5m
          max_retries: 10
        batchwait: 1s
        batchsize: 1048576
        timeout: 10s

    snippets:
      pipelineStages:
        - cri: {}
        - docker: {}

  extraVolumes:
    - name: journal
      hostPath:
        path: /var/log/journal
    - name: audit-logs
      hostPath:
        path: /var/log/audit
    - name: rancher-audit-logs
      hostPath:
        path: /var/log/rancher

  extraVolumeMounts:
    - name: journal
      mountPath: /var/log/journal
      readOnly: true
    - name: audit-logs
      mountPath: /var/log/audit
      readOnly: true
    - name: rancher-audit-logs
      mountPath: /var/log/rancher
      readOnly: true

  serviceMonitor:
    enabled: true

  extraPorts:
    syslog:
      name: tcp-syslog
      containerPort: 1514
      protocol: TCP
      service:
        type: ClusterIP
        port: 1514

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Alloy (OpenTelemetry Collector)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
alloy:
  alloy:
    mounts:
      varlog: true

    service:
      annotations:
        prometheus.io/scrape: "true"
        prometheus.io/port: "12345"
        prometheus.io/path: "/metrics"

    extraPorts:
      - name: otlp-grpc
        port: 4317
        targetPort: 4317
        protocol: TCP
      - name: otlp-http
        port: 4318
        targetPort: 4318
        protocol: TCP

    configMap:
      content: |
        // OTLP receiver configuration
        otelcol.receiver.otlp "default" {
          grpc {
            endpoint = "0.0.0.0:4317"
          }
          http {
            endpoint = "0.0.0.0:4318"
          }
          output {
            metrics = [otelcol.exporter.prometheus.default.input]
            traces  = [otelcol.exporter.otlp.tempo.input]
            logs    = [otelcol.exporter.loki.default.input]
          }
        }

        // Metrics to Prometheus
        otelcol.exporter.prometheus "default" {
          forward_to = [prometheus.remote_write.default.receiver]
        }

        prometheus.remote_write "default" {
          endpoint {
            url = "http://rancher-monitoring-prometheus.cattle-monitoring-system.svc.cluster.local/api/v1/write"
          }
        }

        // Traces to Tempo
        otelcol.exporter.otlp "tempo" {
          client {
            endpoint = "http://tempo.cattle-monitoring-system.svc.cluster.local:4317"
            tls {
              insecure = true
            }
          }
        }

        // Logs to Loki
        otelcol.exporter.loki "default" {
          forward_to = [loki.write.endpoint.receiver]
        }

        loki.write "endpoint" {
          endpoint {
            url = "http://clover-monitoring-loki-gateway.cattle-monitoring-system.svc.cluster.local/loki/api/v1/push"
            batch_size = "1MB"
            batch_wait = "1s"
          }
        }
