apiVersion: monitoring.coreos.com/v1alpha1
kind: AlertmanagerConfig
metadata:
  name: msteams-config
  labels:
    app: alertmanager
spec:
  route:
    groupBy: ['alertname', 'job', 'namespace']
    groupWait: 30s
    groupInterval: 5m
    repeatInterval: 4h
    receiver: msteams
    routes:
      - receiver: "null"
        matchers:
          - matchType: "=~"
            name: alertname
            value: "Watchdog|InfoInhibitor"
      - receiver: msteams-critical
        matchers:
          - matchType: "="
            name: severity
            value: critical
        groupWait: 10s
        groupInterval: 1m
        repeatInterval: 1h
        continue: false
      - receiver: msteams
        matchers:
          - matchType: "="
            name: severity
            value: warning
        groupWait: 30s
        groupInterval: 5m
        repeatInterval: 4h
      - receiver: msteams
        matchers:
          - matchType: "="
            name: severity
            value: info
        groupWait: 30s
        groupInterval: 10m
        repeatInterval: 12h
      - receiver: msteams
  inhibitRules:
    - sourceMatch:
        - matchType: "="
          name: severity
          value: critical
      targetMatch:
        - matchType: "="
          name: severity
          value: warning
      equal: ["alertname", "namespace"]
  receivers:
    - name: "null"
    - name: msteams
      msteamsConfigs:
        - sendResolved: true
          webhookUrl:
            name: alertmanager-msteams-secret
            key: webhook-url
          title: {{ printf "'[%s] %s'" "{{ .Status | toUpper }}" "{{ .CommonLabels.alertname }}" }}
          text: |-
            {{ printf "**Status:** %s | **Severity:** %s | **Cluster:** %s" "{{ .Status | toUpper }}" "{{ .CommonLabels.severity }}" "{{ .CommonLabels.cluster }}" }}

            {{ printf "**Namespace:** %s | **Alerts:** %s" "{{ .CommonLabels.namespace }}" "{{ len .Alerts }}" }}

            ---
            {{ printf "{{ range .Alerts }}" }}
            {{ printf "**%s**" "{{ .Annotations.summary }}" }}

            {{ printf "%s" "{{ .Annotations.description }}" }}

            {{ printf "{{ if .Labels.pod }}**Pod:** %s{{ end }}" "{{ .Labels.pod }}" }}
            {{ printf "{{ if .Labels.container }}**Container:** %s{{ end }}" "{{ .Labels.container }}" }}
            {{ printf "{{ if .Labels.node }}**Node:** %s{{ end }}" "{{ .Labels.node }}" }}
            {{ printf "{{ if .Labels.job }}**Job:** %s{{ end }}" "{{ .Labels.job }}" }}

            {{ printf "**Started:** %s" "{{ .StartsAt.Format \"2006-01-02 15:04:05 UTC\" }}" }}
            {{ printf "{{ if .EndsAt }}**Ended:** %s{{ end }}" "{{ .EndsAt.Format \"2006-01-02 15:04:05 UTC\" }}" }}

            ---
            {{ printf "{{ end }}" }}
            [Grafana](https://grafana.ops.techsecom.io) | [Alertmanager](https://alertmanager.ops.techsecom.io) | [Prometheus](https://prometheus.ops.techsecom.io)
    - name: msteams-critical
      msteamsConfigs:
        - sendResolved: true
          webhookUrl:
            name: alertmanager-msteams-secret
            key: webhook-url
          title: {{ printf "'üö® CRITICAL: %s'" "{{ .CommonLabels.alertname }}" }}
          text: |-
            {{ printf "**üö® CRITICAL ALERT - IMMEDIATE ACTION REQUIRED**" }}

            {{ printf "**Status:** %s | **Cluster:** %s | **Namespace:** %s" "{{ .Status | toUpper }}" "{{ .CommonLabels.cluster }}" "{{ .CommonLabels.namespace }}" }}

            ---
            {{ printf "{{ range .Alerts }}" }}
            {{ printf "**‚ö†Ô∏è %s**" "{{ .Annotations.summary }}" }}

            {{ printf "%s" "{{ .Annotations.description }}" }}

            {{ printf "{{ if .Annotations.runbook_url }}**Runbook:** [View]({{ .Annotations.runbook_url }}){{ end }}" "" }}

            {{ printf "**Affected Resources:**" }}
            {{ printf "{{ if .Labels.pod }}- **Pod:** %s{{ end }}" "{{ .Labels.pod }}" }}
            {{ printf "{{ if .Labels.container }}- **Container:** %s{{ end }}" "{{ .Labels.container }}" }}
            {{ printf "{{ if .Labels.node }}- **Node:** %s{{ end }}" "{{ .Labels.node }}" }}
            {{ printf "{{ if .Labels.deployment }}- **Deployment:** %s{{ end }}" "{{ .Labels.deployment }}" }}
            {{ printf "{{ if .Labels.statefulset }}- **StatefulSet:** %s{{ end }}" "{{ .Labels.statefulset }}" }}

            {{ printf "**Started:** %s" "{{ .StartsAt.Format \"2006-01-02 15:04:05 UTC\" }}" }}
            {{ printf "{{ if .EndsAt }}**Ended:** %s{{ end }}" "{{ .EndsAt.Format \"2006-01-02 15:04:05 UTC\" }}" }}

            ---
            {{ printf "{{ end }}" }}
            [Grafana](https://grafana.ops.techsecom.io) | [Alertmanager](https://alertmanager.ops.techsecom.io)

            {{ printf "**Suggested Actions:**" }}
            1. Check affected resource status
            2. Review recent changes/deployments
            3. Check logs and resource utilization
            4. Escalate if unable to resolve within SLA
